
To Do List / Change Log

0.1 (09 Feb 2014) - Initial Commit
  - Show cluster summary state - nodes, volumes and brick up/down state
  - show summary information per volume - brick up/down count, volume type, 
    volume status and usable capacity summary
  - show errors discovered in summary list at the end of the output

0.2 Complete 2014/02/24
  - align volume state text with nagios monitoring project (DONE)
  - add self heal status (DONE)

0.3 Complete 2014/03/01
  - add check for self heal backlog and show it in volume summary info (DONE)
  - add protocol summary to volume info (DONE)
  - reformatted the summary display to make it more readable/les cluttered (DONE)
  - fix - in vol status sometimes the node name from gluster is not resolved, 
    so pick this up and resolve 'manually' (DONE)

0.4 Complete 2014/03/04
  - add a version check, to abort the run if gluster is not >= 3.4 (DONE)
  - add capacity info to the summary section (DONE)
  - add pct used for each volume (DONE)
  - add volume detail information (DONE)
    - vol components, replica set relationships
  - fix - malformed xml from gluster showing bricks against wrong vols

0.45 Complete 2014/03/06
  - fix release
    - node discovery now validated against initial brick list from a vol info
      avoiding name issues (hopefully!)
    - gstatus detects whether the cluster is name or ip based, and changes 
      name resolution logic accordingly
    - merged volume methods for calculating self heal states
    - added code to check gluster command o/p return code (on vol status) since
      --xml does not set shell return code ($?)
  - New additions
    - added a message count against the cluster state, to immediately show how
      many errors a cluster may have i.e. UNHEALTHY(5) --> 5 errors found

0.5 Complete 2014/03/21
  - add output options for json, keyvalue and console mode (console is default ie. stdout)
  - add client connection counts (glusterfs connections)
  
0.6 planned
  - add config file support
    - space usage triggers on volumes 
    - space usage trigger on bricks

0.7 planned
  - address the blocking problem when a node goes down (commands to a separate thread with a 
    timeout?) 

0.8 planned
  - add brick check to make recommendations on mount point definitions/filesystem, and an option to suppress recommendations

Items being considered


Known BUGS
- invocation after a node down event will block vol status. This needs to be 
  detected and the run aborted to prevent the wrong information being shown to
  the user
- gluster is not returning valid xml when nodes are not present in the config. The problem gets worse with cluster size, and disruption. Current testing has nly allowed 4 node tests to be performed. WORKED AROUND 0.4 onwards



